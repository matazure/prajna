func init(){
    cuda::cuInit(0i32);
}

func setDevice(id: i64){
    cuda::cudaSetDevice(id).tostr();
}

func maxThreadPerBlock(device: i64)->i64{
    var count: i32;
    cuda::cuDeviceGetAttribute(&count, 1i32, device.toi32());
    return count.toi64();
}

func multiProcessorsCount(device: i64)->i64{
    var count: i32;
    cuda::cuDeviceGetAttribute(&count, 16i32, device.toi32());
    return count.toi64();
}

func launchKernel(kernel_function_pointer: i8*, gridDim: Array<i64, 3>, blockDim: Array<i64, 3>, kernel_params: i8**)->i64{
    var re = cuda::cuLaunchKernel(kernel_function_pointer, gridDim[0].tou32(), gridDim[1].tou32(), gridDim[2].tou32(), blockDim[0].tou32(), blockDim[1].tou32(), blockDim[2].tou32(), 0u32, nullptr<i8>::create(), kernel_params, cast<i8**>(nullptr<i8>::create()));
    // "launch re: ".print();
    // re.tostr().print();
    // "\n".print();
    return re.toi64();
}

func launchKernelForDim1(kernel_function_pointer: i8*, paramters: i8**){

}


struct Tensor<Type_ : template, Rank_ : template> {
    data : Type_*;
    shape: Array<i64, Rank_>;
}


implement Tensor<Type_ : template, Rank_: template> {
    @static
    func create(shape :Array<i64, Rank_>)->Tensor<Type_, Rank_>{
        var self: Tensor<Type_, Rank_>;
        self.shape = shape;
        var size = 1;
        for i in 0 to Rank_ {
            size = size * shape[i];
        }
        var bytes = size * sizeof(Type_);
        // bytes.tostr().print();
        var re = cuda::cuMemAlloc(cast<i8**>(&self.data), bytes);
        // "cuMemAlloc".print();
        // re.tostr().print();
        return self;
    }

    func toHost()->::Tensor<Type_, Rank_>{
        var host_tensor = ::Tensor<Type_, Rank_>::create(this.shape);
        var size = 1;
        for i in 0 to Rank_ {
            size = size * this.shape[i];
        }
        // print("toHost: size");
        // size.tostr().print();
        // print("re: ");
        var re =  cuda::cudaMemcpy(cast<i8*>(host_tensor.data), cast<i8*>(this.data), size * sizeof(Type_), 2i32);
        // re.tostr().print();
        return host_tensor;
    }
}

implement ::Tensor<Type_ : template, Rank_: template> {
    func toGpu()->Tensor<Type_, Rank_>{
        var cuda_tensor = Tensor<Type_, Rank_>::create(this.shape);
        var size = 1;
        for i in 0 to Rank_ {
            size = size * this.shape[i];
        }
        // print("tocuda: size");
        // size.tostr().print();
        // print("re: ");
        var re = cuda::cudaMemcpy(cast<i8*>(cuda_tensor.data), cast<i8*>(this.data), size * sizeof(Type_), 1i32);
        // re.tostr().print();
        return cuda_tensor;
    }
}

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.tid.x")
func __thread_idx_x()->u32;

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.tid.y")
func __thread_idx_y()->u32;

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.tid.z")
func __thread_idx_z()->u32;

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.ntid.x")
func __block_dim_x()->u32;

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.ntid.y")
func __block_dim_y()->u32;

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.ntid.z")
func __block_dim_z()->u32;

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.ctaid.x")
func __block_idx_x()->u32;

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.ctaid.y")
func __block_idx_y()->u32;

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.ctaid.z")
func __block_idx_z()->u32;

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.nctaid.x")
func __grid_dim_x()->u32;

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.nctaid.y")
func __grid_dim_y()->u32;

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.nctaid.z")
func __grid_dim_z()->u32;

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.warpsize")
func __warp_size()->u32;

@target("nvptx")
func threadIndex()->Array<i64, 3> {
    return [__thread_idx_x().toi64(), __thread_idx_y().toi64(), __thread_idx_z().toi64()];
}

@target("nvptx")
func blockDim()->Array<i64, 3> {
    return [__block_dim_x().toi64(), __block_dim_y().toi64(), __block_dim_z().toi64()];
}

@target("nvptx")
func blockIndex()->Array<i64, 3> {
    return [__block_idx_x().toi64(), __block_idx_y().toi64(), __block_idx_z().toi64()];
}

@target("nvptx")
func gridDim()->Array<i64, 3> {
    return [__grid_dim_x().toi64(), __grid_dim_y().toi64(), __grid_dim_z().toi64()];
}
